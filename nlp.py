import streamlit as st
import joblib
from streamlit import session_state as _state
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import confusion_matrix
import re
import string
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score


def main():
    # Register your pages
    pages = {
        "–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞": page_first,
        "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞": page_second,
        "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞": page_third,
        "–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏": page_forth
    }

    st.sidebar.title("–í–µ–±-—Ä–µ—Å—É—Ä—Å—Ç–∞—Ä–¥–∞“ì—ã –∫–∏–±–µ—Ä“õ–∞—É—ñ–ø—Ç—ñ –º”ô—Ç—ñ–Ω–¥–µ—Ä–¥—ñ –∞–Ω—ã“õ—Ç–∞—É")

    # Widget to select your page, you can choose between radio buttons or a selectbox
    page = st.sidebar.radio("–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É", tuple(pages.keys()))
    # page = st.sidebar.radio("Select your page", tuple(pages.keys()))

    # Display the selected page with the session state
    pages[page]()


def page_first():
    st.header(
        """–ë“±–ª –∂“±–º—ã—Å—Ç–∞ –∫–∏–±–µ—Ä“õ–∞—É—ñ–ø—Ç—ñ –º”ô—Ç—ñ–Ω —Ä–µ—Ç—ñ–Ω–¥–µ `—ç–π–¥–∂–∏–∑–º`, `—ç–π–±–ª–∏–∑–º` –∂”ô–Ω–µ `–∞–¥–∞–º–¥—ã ”ô–ª–µ—É–º–µ—Ç—Ç—ñ–∫ –∫–µ–º—Å—ñ—Ç—É–≥–µ` “õ–∞—Ç—ã—Å—Ç—ã –º”ô—Ç—ñ–Ω–¥–µ—Ä “õ–∞—Ä–∞—Å—Ç—ã—Ä—ã–ª–∞–¥—ã.
                 
–≠–π–¥–∂–∏–∑–º –∞–¥–∞–º–Ω—ã“£  –∂–∞—Å—ã –±–æ–π—ã–Ω—à–∞ –∫–µ–º—Å—ñ—Ç—É–¥—ñ “õ–∞–º—Ç–∏—Ç—ã–Ω –º”ô—Ç—ñ–Ω–¥–µ—Ä. –ë“±–ª –º”ô—Ç—ñ–Ω–¥–µ—Ä–¥–µ —Ç–µ“£ –Ω–µ–≥—ñ–∑–¥–µ ”©–∑–∞—Ä–∞ ”ô—Ä–µ–∫–µ—Ç—Ç–µ—Å—É–≥–µ –∂”ô–Ω–µ –±–µ–ª–≥—ñ–ª—ñ –±—ñ—Ä –∂–∞—Å ”©–ª—à–µ–º—ñ–Ω–µ —Å”ô–π–∫–µ—Å –∫–µ–ª–µ—Ç—ñ–Ω –∞–¥–∞–º–¥–∞—Ä–º–µ–Ω “ì–∞–Ω–∞ –∂“±–º—ã—Å —ñ—Å—Ç–µ—É–≥–µ –¥–∞–π—ã–Ω –µ–∫–µ–Ω–¥—ñ–≥—ñ –∫”©—Ä—ñ–Ω–µ–¥—ñ. 
–ë—ñ—Ä—ñ–∫–∫–µ–Ω “∞–ª—Ç—Ç–∞—Ä “∞–π—ã–º—ã–Ω—ã“£ —ç–π–¥–∂–∏–∑–º –º”ô—Å–µ–ª–µ—Å—ñ —Ç—É—Ä–∞–ª—ã –∂–∞“£–∞ –µ—Å–µ–±—ñ–Ω–µ —Å”ô–π–∫–µ—Å, ”ô–ª–µ–º–¥–µ–≥—ñ ”ô—Ä–±—ñ—Ä –µ–∫—ñ–Ω—à—ñ –∞–¥–∞–º —Ñ–∏–∑–∏–∫–∞–ª—ã“õ –∂”ô–Ω–µ –ø—Å–∏—Ö–∏–∫–∞–ª—ã“õ –¥–µ–Ω—Å–∞—É–ª—ã“ì—ã–Ω—ã“£ –Ω–∞—à–∞—Ä–ª–∞—É—ã–Ω–∞ –∂”ô–Ω–µ –µ–≥–¥–µ –∂–∞—Å—Ç–∞“ì—ã –∞–¥–∞–º–¥–∞—Ä–¥—ã“£ ”©–º—ñ—Ä —Å“Ø—Ä—É —Å–∞–ø–∞—Å—ã–Ω—ã“£ —Ç”©–º–µ–Ω–¥–µ—É—ñ–Ω–µ ”ô–∫–µ–ª–µ—Ç—ñ–Ω —ç–π–¥–∂–∏—Å—Ç—ñ–∫ –∫”©–∑“õ–∞—Ä–∞—Å—Ç–∞—Ä–¥—ã “±—Å—Ç–∞–Ω–∞–¥—ã –¥–µ–ø —Å–∞–Ω–∞–ª–∞–¥—ã.
“ö–∞—Ä–∞—Å—Ç—ã—Ä—ã–ª–∞—Ç—ã–Ω –µ–∫—ñ–Ω—à—ñ –º”ô—Å–µ–ª–µ - –µ“£–±–µ–∫–∫–µ “õ–∞–±—ñ–ª–µ—Ç—Ç—ñ –∞–¥–∞–º–¥–∞—Ä –º“Ø–≥–µ–¥–µ–∫—Ç—ñ–≥—ñ –±–∞—Ä –∞–¥–∞–º–¥–∞—Ä–¥–∞–Ω “õ–∞–ª—ã–ø—Ç—ã –∂”ô–Ω–µ –∂–æ“ì–∞—Ä—ã –¥–µ–ø —Å–∞–Ω–∞–ª–∞—Ç—ã–Ω –∫–µ–º—Å—ñ—Ç—É—à—ñ–ª—ñ–∫ —Ç“Ø—Ä—ñ. –≠–π–±–ª–∏–∑–º –º“Ø–≥–µ–¥–µ–∫—Ç—ñ–≥—ñ –±–∞—Ä, —Å–æ–∑—ã–ª–º–∞–ª—ã —Å–æ–º–∞—Ç–∏–∫–∞–ª—ã“õ –Ω–µ–º–µ—Å–µ –ø—Å–∏—Ö–∏–∫–∞–ª—ã“õ –∞—É—ã—Ç“õ—É–ª–∞—Ä—ã –±–∞—Ä –∞–¥–∞–º–¥–∞—Ä“ì–∞ ”ô–ª–µ—É–º–µ—Ç—Ç—ñ–∫ –±–µ–π—ñ–º–¥—ñ–ª—ñ–∫ –ø–µ–Ω –∂“Ø–π–µ–ª—ñ–∫ –∫–µ–º—Å—ñ—Ç—É—à—ñ–ª—ñ–∫—Ç—ñ “õ–∞–º—Ç–∏–¥—ã. –û–ª –∞–¥–∞–º–¥–∞—Ä–¥—ã —Ç–µ–∫ —à–µ–∫—Ç–µ—É–ª—ñ –º“Ø–º–∫—ñ–Ω–¥—ñ–∫—Ç–µ—Ä—ñ–Ω–µ –Ω–∞–∑–∞—Ä –∞—É–¥–∞—Ä–∞ –æ—Ç—ã—Ä—ã–ø —Å–∏–ø–∞—Ç—Ç–∞–π–¥—ã –∂”ô–Ω–µ –æ–ª–∞—Ä–¥—ã“£ “õ–∞–∂–µ—Ç—Ç—ñ–ª—ñ–∫—Ç–µ—Ä—ñ–Ω –±–∞—Å“õ–∞ –∞–¥–∞–º–¥–∞—Ä–º–µ–Ω —Å–∞–ª—ã—Å—Ç—ã—Ä“ì–∞–Ω–¥–∞ –µ–∫—ñ–Ω—à—ñ –æ—Ä—ã–Ω“ì–∞ “õ–æ—è–¥—ã. –û—Å—ã –Ω–µ–≥—ñ–∑–¥–µ –º“Ø–≥–µ–¥–µ–∫—Ç—ñ–≥—ñ –±–∞—Ä –∞–¥–∞–º–¥–∞—Ä –±–µ–ª–≥—ñ–ª—ñ –±—ñ—Ä –¥–∞“ì–¥—ã–ª–∞—Ä“ì–∞ –Ω–µ–º–µ—Å–µ –º—ñ–Ω–µ–∑-“õ“±–ª—ã“õ –µ—Ä–µ–∫—à–µ–ª—ñ–∫—Ç–µ—Ä—ñ–Ω–µ –±–∞–π–ª–∞–Ω—ã—Å—Ç—ã –Ω–µ–º–µ—Å–µ –∫–µ—Ä—ñ—Å—ñ–Ω—à–µ “õ–∞–±—ã–ª–¥–∞–Ω–±–∞–π–¥—ã[5].
“Æ—à—ñ–Ω—à—ñ –º”ô—Å–µ–ª–µ ‚Äì–∞–¥–∞–º–Ω—ã“£ –¥—ñ–Ω—ñ, –Ω”ô—Å—ñ–ª—ñ, ”ô–ª–µ—É–º–µ—Ç—Ç—ñ–∫ –∂–∞“ì–¥–∞–π—ã, —à—ã“ì—É —Ç–µ–≥—ñ, “±–ª—Ç—ã–Ω–∞ –±–∞–π–ª–∞–Ω—ã—Å—Ç—ã –∫–µ–º—Å—ñ—Ç—É —Ç“Ø—Ä—ñ."""
    )


def page_second():
    st.title("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    st.warning("–ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã —Ñ–æ—Ä–º–∞—Ç–∞ .csv", icon="‚ö†Ô∏è")
    uploaded_file = upload_file()
    if uploaded_file is not None:
        _, file_extension = os.path.splitext(uploaded_file.name)
        if file_extension.lower() == ".csv":
            try:
                df = pd.read_csv(uploaded_file)
                if "original_data" not in st.session_state:
                    st.session_state["original_data"] = df
                else:
                    st.session_state["original_data"] = df
                if "uploaded" not in st.session_state:
                    st.session_state["uploaded"] = True
            except Exception as e:
                st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}", icon="üö®")
        else:
            st.error("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—É CSV", icon="üö®")


def page_third():
    if "uploaded" not in st.session_state:
        st.info("–°–Ω–∞—á–∞–ª–∞ –≤—ã –¥–æ–ª–∂–Ω—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
    else:
        if "data" not in st.session_state:
            st.session_state["data"] = st.session_state["original_data"].copy()
        df = st.session_state["original_data"].copy()
        st.title("1. –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
        st.dataframe(df, hide_index=True)
        
        columns = list(df.columns)
        # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
        column_for_preprocessing = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
        options=columns,
        key=persist("column_for_preprocessing"))

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        change_df = df
        change_df = process_dataframe(change_df, column_for_preprocessing)

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        st.dataframe(change_df, hide_index=True)

        st.title("2.–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")

        color_theme_list = [
            "Blues",
            "viridis",
            "plasma",
            "inferno",
            "magma",
            "cividis",
            "Greys",
            "Purples",
            "Greens",
            "Oranges",
            "Reds",
            "YlOrBr",
            "YlOrRd",
            "OrRd",
            "PuRd",
            "RdPu",
            "BuPu",
            "GnBu",
            "PuBu",
            "YlGnBu",
            "PuBuGn",
            "BuGn",
            "YlGn",
            "PiYG",
            "PRGn",
            "BrBG",
            "PuOr",
            "RdGy",
            "RdBu",
            "RdYlBu",
            "RdYlGn",
            "Spectral",
            "coolwarm",
            "bwr",
            "seismic",
        ]
        plots = [
            "Line Plot",
            "Scatter Plot",
            "Histogram Plot",
            "Box Plot",
            "Density Plot",
        ]
        visualizations = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –≥—Ä–∞—Ñ–∏–∫ –∫–æ—Ç–æ—Ä—ã–π –≤—ã —Ö–æ—Ç–∏—Ç–µ —É–≤–∏–¥–µ—Ç—å",
            plots,
            key=persist("select_type_of_visualization_for_dataset"),
        )
        x_axis = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω –ø–æ –æ—Å–∏ X",
            change_df.columns,
            key=persist("select_column_for_x_axis"),
        )
        y_axis = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω –ø–æ –æ—Å–∏ Y",
            change_df.columns,
            key=persist("select_column_for_y_axis"),
        )
        color_theme_list = [
            "blues",
            "cividis",
            "greens",
            "inferno",
            "magma",
            "plasma",
            "reds",
            "turbo",
            "viridis",
        ]

        use_hue = create_toggle(
            "use_hue_toggle", "–í–∫–ª—é—á–∏—Ç—å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É —Ç–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ü–≤–µ—Ç—É"
        )

        if use_hue:
            hue = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä, —Å –ø–æ–º–æ—â—å—é –∫–æ—Ç–æ—Ä–æ–≥–æ –±—É–¥—É—Ç –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å—Å—è —Ç–æ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ü–≤–µ—Ç—É",
                change_df.columns,
                key="select_hue",  # Assuming persist() function is defined elsewhere to handle session state
            )
            selected_color_theme = st.selectbox(
                "Select a color theme",
                color_theme_list,
                key=persist("select_color_theme"),
            )
        else:
            hue = None
            selected_color_theme = st.color_picker(
                "Pick A Color", "#00f900", key=persist("color")
            )

        # Then, depending on the type of visualization selected by the user:
        if visualizations == "Line Plot":
            line_chart(
                change_df,
                x_axis,
                y_axis,
                input_color_theme=selected_color_theme,
                hue=hue,
            )
        elif visualizations == "Scatter Plot":
            scatter_plot(
                change_df,
                x_axis,
                y_axis,
                input_color_theme=selected_color_theme,
                hue=hue,
            )
        elif visualizations == "Histogram Plot":
            count_of_bins = st.select_slider(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫", range(2, 100)
            )
            histogram(
                change_df,
                x_axis,
                input_color_theme=selected_color_theme,
                hue=hue,
                bin_count=count_of_bins,
            )
        elif visualizations == "Box Plot":
            box_plot(
                change_df,
                x_axis,
                y_axis,
                input_color_theme=selected_color_theme,
                hue=hue,
            )
        elif visualizations == "Density Plot":
            density_plot(
                change_df, x_axis, input_color_theme=selected_color_theme, hue=hue
            )

        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è"):
                st.session_state["data"] = change_df
                st.success("–ò–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")
        with col2:
            if st.button("–û—á–∏—Å—Ç–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è"):
                st.session_state["data"] = st.session_state["original_data"].copy()
                reset_application_state()
                st.warning("–ò–∑–º–µ–Ω–µ–Ω–∏—è —Å–±—Ä–æ—à–µ–Ω—ã")


def page_forth():
    if "data" not in st.session_state:
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ")
    else:
        complete_df = st.session_state["data"]
        st.title("1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª–∏")
        st.dataframe(complete_df, hide_index=True)
        
        # Ensure the persisted value is valid
        if "select_x_column" in st.session_state:
            if st.session_state["select_x_column"] not in complete_df.columns:
                st.session_state["select_x_column"] = complete_df.columns[0]

        if "select_y_column" in st.session_state:
            if st.session_state["select_y_column"] not in complete_df.columns:
                st.session_state["select_y_column"] = complete_df.columns[0]

        x_column = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ `X` —Å—Ç–æ–ª–±–µ—Ü —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏:",
            complete_df.columns,
            key=persist("select_x_column"),
        )
        y_column = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ `Y` —Ü–µ–ª–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä, –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –±—É–¥—É—Ç —Å–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω—ã:",
            complete_df.columns,
            key=persist("select_y_column"),
        )
        X = complete_df[x_column]
        y = complete_df[y_column]
        col1, col2, col3 = st.columns([5, 0.3, 1])
        with col1:
            st.subheader("X:")
            st.dataframe(X, hide_index=True)
            st.write("–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ :", X.shape)
        with col3:
            st.subheader("y:")
            st.dataframe(y, hide_index=True)
            st.write("–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ :", y.shape[0])

        size = st.slider(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞:",
            0.0,
            1.0,
            0.2,
            step=0.01,
            key=persist("slider_size_of_test_dataset"),
        )
        st.write(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ {size * 100} % –æ—Ç –æ–±—â–µ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞")
        X_train, X_test, y_train, y_test = custom_train_test_split(X, y, size=size)

        col1, col2, col3 = st.columns([5, 0.3, 1])
        with col1:
            st.subheader("X_train:")
            st.dataframe(X_train, hide_index=True)
            st.write("–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ :", X_train.shape)
        with col3:
            st.subheader("y_train:")
            st.dataframe(y_train, hide_index=True)
            st.write("–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ :", y_train.shape[0])
        st.divider()
        col4, col5, col6 = st.columns([5, 0.3, 1])
        with col4:
            st.subheader("X_test:")
            st.dataframe(X_test, hide_index=True)
            st.write("–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ :", X_test.shape)
        with col6:
            st.subheader("y_test:")
            st.dataframe(y_test, hide_index=True)
            st.write("–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ :", y_test.shape[0])

        st.info("–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω—É–∂–Ω–æ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é!")
        vectorizer = create_toggle("vectorizer_toggle", "–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–∞")
        if vectorizer:
            tfidf_vectorizer = TfidfVectorizer()
            tfidf_train_vectors = tfidf_vectorizer.fit_transform(X_train)
            tfidf_test_vectors = tfidf_vectorizer.transform(X_test)

            st.write(f"X_train = {tfidf_train_vectors}")
            st.write(f"X_test = {tfidf_test_vectors}")

        st.title("2. –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏")
        classification_models = [
            "Decision Tree CLassification",
            "Random Forest Classification",
            "Support Vector Machine CLassification",
            "Multi Layer Perceptron Classifier",
        ]

        options_clf = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: ",
                classification_models,
                key=persist("select_classification_model"),
            )
            
        if options_clf == "Decision Tree CLassification":
            options_decision_tree_classification = st.radio(
                "–°–¥–µ–ª–∞–π—Ç–µ –≤—ã–±–æ—Ä:",
                ["–í—ã–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä—É—á–Ω—É—é", "–í—ã–±—Ä–∞—Ç—å –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –º–æ–¥–µ–ª—å"],
                key=persist("choose_parameters_for_decision_tree_classification"),
            )
            if options_decision_tree_classification == "–í—ã–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä—É—á–Ω—É—é":
                col1, col2 = st.columns(2)
                with col1:
                    max_depth = st.number_input(
                        "`max_depth` –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞",
                        1,
                        100,
                        3,
                        key=persist(
                            "number_for_decision_tree_classification_max_depth"
                        ),
                    )
                with col2:
                    min_samples_split = st.number_input(
                        "`min_samples_split` –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —É–∑–ª–∞",
                        2,
                        100,
                        2,
                        key=persist(
                            "number_for_decision_tree_classification_min_samples_split"
                        ),
                    )
                col3, col4 = st.columns(2)
                with col3:
                    min_samples_leaf = st.number_input(
                        "`min_samples_leaf` –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –≤ —É–∑–ª–µ –ª–∏—Å—Ç–∞",
                        1,
                        100,
                        1,
                        key=persist(
                            "number_for_decision_tree_classification_min_samples_leaf"
                        ),
                    )
                with col4:
                    ccp_alpha = st.slider(
                        "`ccp_alpha` –ü–∞—Ä–∞–º–µ—Ç—Ä —Å–ª–æ–∂–Ω–æ—Å—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å - —Å–ª–æ–∂–Ω–æ—Å—Ç—å",
                        0.0,
                        1.0,
                        0.0,
                        step=0.01,
                        key=persist("slider_decision_tree_classification_ccp_alpha"),
                    )
                criterion_for_decision_tree_classification = [
                    "gini",
                    "entropy",
                    "log_loss",
                ]
                criterion = st.selectbox(
                    "`criterion` –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è",
                    criterion_for_decision_tree_classification,
                    key=persist("select_criterion_decision_tree_classification"),
                )

                model = custom_decision_tree_classification(
                    criterion_c=criterion,
                    max_depth_c=max_depth,
                    min_samples_split_c=min_samples_split,
                    min_samples_leaf_c=min_samples_leaf,
                    ccp_alpha_c=ccp_alpha,
                )
            else:
                model = DecisionTreeClassifier()

        elif options_clf == "Random Forest Classification":
            options_random_forest_classification = st.radio(
                "–°–¥–µ–ª–∞–π—Ç–µ –≤—ã–±–æ—Ä:",
                ["–í—ã–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä—É—á–Ω—É—é", "–í—ã–±—Ä–∞—Ç—å –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –º–æ–¥–µ–ª—å"],
                key=persist("choose_parameters_for_random_forest_classification"),
            )
            if options_random_forest_classification == "–í—ã–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä—É—á–Ω—É—é":
                n_estimators = st.slider(
                    "`n_estimators` –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ –≤ –ª–µ—Å—É",
                    50,
                    1000,
                    100,
                    key=persist("number_for_random_forest_classification_n_estimators"),
                )
                col1, col2 = st.columns(2)
                with col1:
                    max_depth = st.number_input(
                        "`max_depth` –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞",
                        1,
                        100,
                        3,
                        key=persist(
                            "number_for_random_forest_classification_max_depth"
                        ),
                    )
                with col2:
                    min_samples_split = st.number_input(
                        "`min_samples_split` –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —É–∑–ª–∞",
                        2,
                        100,
                        2,
                        key=persist(
                            "number_for_random_forest_classification_min_samples_split"
                        ),
                    )
                col3, col4 = st.columns(2)
                with col3:
                    min_samples_leaf = st.number_input(
                        "`min_samples_leaf` –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –≤ —É–∑–ª–µ –ª–∏—Å—Ç–∞",
                        1,
                        100,
                        1,
                        key=persist(
                            "number_for_random_forest_classification_min_samples_leaf"
                        ),
                    )
                with col4:
                    ccp_alpha = st.slider(
                        "`ccp_alpha` –ü–∞—Ä–∞–º–µ—Ç—Ä —Å–ª–æ–∂–Ω–æ—Å—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å - —Å–ª–æ–∂–Ω–æ—Å—Ç—å",
                        0.0,
                        1.0,
                        0.0,
                        step=0.01,
                        key=persist("slider_random_forest_classification_ccp_alpha"),
                    )
                criterion_for_random_forest_classification = [
                    "gini",
                    "entropy",
                    "log_loss",
                ]
                criterion = st.selectbox(
                    "`criterion` –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è",
                    criterion_for_random_forest_classification,
                    key=persist("select_criterion_random_forest_classification"),
                )

                model = custom_random_forest_classification(
                    n_estimators,
                    criterion,
                    max_depth,
                    min_samples_split,
                    min_samples_leaf,
                    ccp_alpha,
                )
            else:
                model = RandomForestClassifier()

        elif options_clf == "Support Vector Machine CLassification":
            options_svm_classification = st.radio(
                "–°–¥–µ–ª–∞–π—Ç–µ –≤—ã–±–æ—Ä:",
                ["–í—ã–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä—É—á–Ω—É—é", "–í—ã–±—Ä–∞—Ç—å –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –º–æ–¥–µ–ª—å"],
                key=persist("choose_parameters_for_svm_classification"),
            )
            if options_svm_classification == "–í—ã–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä—É—á–Ω—É—é":
                col1, col2 = st.columns(2)
                with col1:
                    kernel = st.selectbox(
                        "`kernel` –£–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–∏–ø —è–¥—Ä–∞, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ –∞–ª–≥–æ—Ä–∏—Ç–º–µ.",
                        ["linear", "poly", "rbf", "sigmoid", "precomputed"],
                        key=persist("select_kernel_svm_classification"),
                    )
                with col2:
                    degree = st.number_input(
                        "`degree` –°—Ç–µ–ø–µ–Ω—å –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ —è–¥—Ä–∞ ('poly')",
                        1,
                        10,
                        3,
                        key=persist("number_for_svm_classification_degree"),
                    )
                model = custom_svc(kernel, degree)
            else:
                model = SVC()
        else:
            options_mlp_classification = st.radio(
                "–°–¥–µ–ª–∞–π—Ç–µ –≤—ã–±–æ—Ä:",
                ["–í—ã–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä—É—á–Ω—É—é", "–í—ã–±—Ä–∞—Ç—å –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –º–æ–¥–µ–ª—å"],
                key=persist("choose_parameters_for_mlpc"),
            )
            if options_mlp_classification == "–í—ã–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä—É—á–Ω—É—é":
                col1, col2 = st.columns(2)
                with col1:
                    activation = st.selectbox("`activation` –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –¥–ª—è —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è", ["relu", "logistic", "tanh", "identity"], key=persist("select_activation_mlpc"))
                with col2:
                    solver = st.selectbox("`solver` –†–µ—à–∞—é—â–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–∞", ["adam", "lbfgs", "sgd"],  key=persist("select_solver_mlpc"))
                model = custom_mlp_classifier(activation_func_c=activation, solver_c=solver)
            else:
                model = MLPClassifier()

        st.write(model)

        color_theme_list = [
            "Blues",
            "viridis",
            "plasma",
            "inferno",
            "magma",
            "cividis",
            "Greys",
            "Purples",
            "Greens",
            "Oranges",
            "Reds",
            "YlOrBr",
            "YlOrRd",
            "OrRd",
            "PuRd",
            "RdPu",
            "BuPu",
            "GnBu",
            "PuBu",
            "YlGnBu",
            "PuBuGn",
            "BuGn",
            "YlGn",
            "PiYG",
            "PRGn",
            "BrBG",
            "PuOr",
            "RdGy",
            "RdBu",
            "RdYlBu",
            "RdYlGn",
            "Spectral",
            "coolwarm",
            "bwr",
            "seismic",
        ]
        show_results_visualizations = False

        if st.checkbox("–û–±—É—á–∏—Ç—å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–¥–µ–ª—å", key=persist("checkbox_model_see")):
            model, pred = train_and_predict(model, tfidf_train_vectors, y_train, tfidf_test_vectors)
            acc = accuracy_score(y_test, pred)
            f1 = f1_score(y_test, pred, average='macro')  
            precision = precision_score(y_test, pred, average='macro')  
            recall = recall_score(y_test, pred, average='macro')
            classification_score = pd.DataFrame(
                {
                    "Accuracy": acc,
                    "F1_score": f1,
                    "Precision": precision,
                    "Recall": recall,
                },
                index=[0],
            )
            st.write("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
            show_results_visualizations = True
            st.dataframe(classification_score, hide_index=True)

        # Assuming your model is named `model` and is already trained
        filename = "Completed_model.joblib"
        joblib.dump(model, filename)  # Save the model to a file

        # Open the file in binary mode to pass to the download button
        with open(filename, "rb") as file:
            st.download_button(
                label="C–∫–∞—á–∞—Ç—å –≥–æ—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å",
                data=file,
                file_name=filename,
                mime="application/octet-stream",
            )

        st.title("3. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        if show_results_visualizations:
            color = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ö–µ–º—É —Ü–≤–µ—Ç–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏", color_theme_list)
            confusion_matrix_visualization(y_test, pred, color)
        else:
            st.info("–°–Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∏ –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        
        st.title("4. –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é")
        st.image("107169631-1671636988973-gettyimages-1245766411-porzycki-elonmusk221221_npQVV.jpeg")
        message = st.text_input("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ", key=persist("message_input"))
        if len(message) == 0:
            st.info("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ") 
        else:
            prediction = model.predict(tfidf_vectorizer.transform([message]))
            st.write(f"Result = {prediction}")





_PERSIST_STATE_KEY = f"{__name__}_PERSIST"


def persist(key: str) -> str:
    """Mark widget state as persistent."""
    if _PERSIST_STATE_KEY not in _state:
        _state[_PERSIST_STATE_KEY] = set()

    _state[_PERSIST_STATE_KEY].add(key)

    return key


initial_state = {"uploaded": True}

initial_state_data = {"uploaded": False}


def load_widget_state():
    """Load persistent widget state."""
    if _PERSIST_STATE_KEY in _state:
        _state.update(
            {
                key: value
                for key, value in _state.items()
                if key in _state[_PERSIST_STATE_KEY]
            }
        )


def reset_application_state():
    global _state
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–¥–∞–ª–µ–Ω—ã
    preserved_values = {
        key: _state[key] for key in ["data", "original_data"] if key in _state
    }

    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    _state.clear()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    _state.update(
        initial_state.copy()
    )  # –ò—Å–ø–æ–ª—å–∑—É–µ–º .copy() –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Å–ª–æ–≤–∞—Ä–µ

    # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    _state.update(preserved_values)
    st.rerun()


def reset_application_state_with_data():
    global _state

    _state.update(
        initial_state_data.copy()
    )  # –ò—Å–ø–æ–ª—å–∑—É–µ–º .copy() –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Å–ª–æ–≤–∞—Ä–µ

    _state.clear()

    st.rerun()



def upload_file():
    """
    Presents a file uploader widget and returns the uploaded file object.

    This function creates a file uploader in a Streamlit app with the specified prompt message.
    Users can upload a file through the UI. If a file is uploaded, the function returns the
    file object provided by Streamlit, allowing further processing of the file. If no file is
    uploaded, the function returns None.

    Returns:
    - uploaded_file (UploadedFile or None): The file object uploaded by the user through the
      file uploader widget. The object contains methods and attributes to access and read the file's
      content. Returns None if no file has been uploaded.

    Example usage:
    ```
    uploaded_file = upload_file()
    if uploaded_file is not None:
        # Process the file
        st.write("File uploaded:", uploaded_file.name)
    else:
        st.write("No file uploaded.")
    ```
    """
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª")
    if uploaded_file is not None:
        return uploaded_file
    return None


def line_chart(data, x_axis, y_axis, input_color_theme, hue=None):
    # If hue is provided, color the circles based on the hue column and the input color theme.
    # If hue is None, all circles will be colored red.
    if hue:
        color_encoding = alt.Color(hue, scale=alt.Scale(scheme=input_color_theme))
    else:
        color_encoding = alt.value(
            input_color_theme
        )  # Directly set the color to red if hue is not provided

    c = (
        alt.Chart(data)
        .mark_line()
        .encode(x=x_axis, y=y_axis, color=color_encoding)
        .interactive()
    )

    st.altair_chart(c, use_container_width=True)


def scatter_plot(data, x_axis, y_axis, input_color_theme, hue=None):
    # If hue is provided, color the circles based on the hue column and the input color theme.
    # If hue is None, all circles will be colored red.
    if hue:
        color_encoding = alt.Color(hue, scale=alt.Scale(scheme=input_color_theme))
    else:
        color_encoding = alt.value(
            input_color_theme
        )  # Directly set the color to red if hue is not provided

    c = (
        alt.Chart(data)
        .mark_circle()
        .encode(x=x_axis, y=y_axis, color=color_encoding)
        .interactive()
    )

    st.altair_chart(c, use_container_width=True)


import altair as alt
import streamlit as st


def histogram(data, x_axis, input_color_theme, bin_count, hue=None):
    """
    Create a histogram with configurable number of bins (columns).

    :param data: pd.DataFrame - The data to visualize.
    :param x_axis: str - The column name to use for the x-axis.
    :param input_color_theme: str - The color theme for the bars.
    :param bin_count: int - The number of bins (columns) for the histogram.
    :param hue: str or None - The column name for color encoding, if any.
    """
    # If hue is provided, color the bars based on the hue column and the input color theme.
    # If hue is None, all bars will be colored with the input color theme.
    if hue:
        color_encoding = alt.Color(hue, scale=alt.Scale(scheme=input_color_theme))
    else:
        color_encoding = alt.value(
            input_color_theme
        )  # Directly set the color if hue is not provided

    chart = (
        alt.Chart(data)
        .mark_bar()
        .encode(
            x=alt.X(x_axis, bin=alt.Bin(maxbins=bin_count)),  # Set the number of bins
            y="count()",
            color=color_encoding,
        )
        .interactive()
    )

    st.altair_chart(chart, use_container_width=True)


def box_plot(data, x_axis, y_axis, input_color_theme, hue=None):
    # If hue is provided, color the box plot based on the hue column and the input color theme.
    # If hue is None, all plots will be colored with the input color theme.
    if hue:
        color_encoding = alt.Color(hue, scale=alt.Scale(scheme=input_color_theme))
    else:
        color_encoding = alt.value(
            input_color_theme
        )  # Directly set the color to red if hue is not provided

    chart = (
        alt.Chart(data)
        .mark_boxplot()
        .encode(x=x_axis, y=y_axis, color=color_encoding)
        .interactive()
    )

    st.altair_chart(chart, use_container_width=True)


def density_plot(data, x_axis, input_color_theme, hue=None):
    # Start with the base chart
    chart = alt.Chart(data)

    # Apply the density transformation conditionally based on hue
    if hue:
        # If hue is provided, calculate density with grouping
        chart = chart.transform_density(
            density=x_axis,
            as_=[x_axis, "density"],
            groupby=[hue],  # Ensure this is a list
        )
    else:
        # If hue is not provided, calculate density without grouping
        chart = chart.transform_density(density=x_axis, as_=[x_axis, "density"])

    # Apply the rest of the encoding
    chart = chart.mark_area().encode(
        x=f"{x_axis}:Q",
        y="density:Q",
        color=(
            alt.Color(hue, scale=alt.Scale(scheme=input_color_theme))
            if hue
            else alt.value(input_color_theme)
        ),
    )

    st.altair_chart(chart, use_container_width=True)


def create_toggle(session_name: str, name: str, status=False) -> bool:
    """
    Creates a toggle switch in a Streamlit app and manages its state across reruns.

    This function displays a toggle switch with the label specified by the 'name' parameter.
    It uses Streamlit's session state to keep track of the toggle's position (on/off) across reruns.
    The current state of the toggle is stored in `st.session_state` using a key provided by the
    'session_name' parameter.

    Parameters:
    - session_name (str): The key used to store the toggle's state in `st.session_state`.
                          This key should be unique to each toggle to prevent state conflicts.
    - name (str): The label displayed next to the toggle switch in the UI.

    Returns:
    - bool: The current state of the toggle (True for on, False for off).

    Example:
    ```
    delete_column = create_toggle('delete_status', '–£–¥–∞–ª–∏—Ç—å')
    if delete_column:
        st.write("Toggle is ON - deletion logic can be placed here.")
    else:
        st.write("Toggle is OFF - no deletion occurs.")
    ```
    """
    # Initialize toggle status in session_state if it doesn't exist
    if session_name not in st.session_state:
        st.session_state[session_name] = False

    # Display the toggle and assign its current value based on session_state
    toggle = st.toggle(name, value=st.session_state[session_name], disabled=status)

    # Update session state based on the toggle's position
    if toggle != st.session_state[session_name]:
        st.session_state[session_name] = toggle
        st.rerun()
    return toggle


def clean_text(text):
    """
    Cleans the input text by removing tabs, extra spaces, punctuation, and converting to lowercase.

    :param text: str - The input text to be cleaned.
    :return: str - The cleaned text.
    """
    if not isinstance(text, str):
        text = str(text)
    text = re.sub(r"\t+", " ", text)  # –ó–∞–º–µ–Ω—è–µ—Ç —Ç–∞–±—É–ª—è—Ü–∏–∏ –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r"\s+", " ", text)  # –£–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = text.strip()  # –£–±–∏—Ä–∞–µ—Ç –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏
    text = text.lower()  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä
    punctuationfree = "".join(
        [i for i in text if i not in string.punctuation]
    )  # –£–±–∏—Ä–∞–µ—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
    return punctuationfree


def count_words(text):
    """
    Counts the number of words in the input text.

    :param text: str - The input text to be counted.
    :return: int - The word count.
    """
    if not isinstance(text, str):
        text = str(text)
    words = text.split()
    return len(words)


def process_dataframe(data, column_name):
    """
    Cleans the text in the specified column and adds a 'Word Count' column to the DataFrame.

    :param data: pd.DataFrame - The DataFrame containing the sentences.
    :param column_name: str - The name of the column containing the sentences.
    :return: pd.DataFrame - The DataFrame with cleaned text and an added 'Word Count' column.
    """
    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–µ
    data[column_name] = data[column_name].apply(clean_text)
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–ª–æ–≤
    data["Word Count"] = data[column_name].apply(count_words)
    return data


def delete_columns(data, columns):
    """
    Removes specified columns from a DataFrame.

    This function takes a DataFrame and a list of column names to be removed. It returns a new DataFrame with the specified
    columns removed, leaving the original DataFrame unchanged.

    Parameters:
    - data (pd.DataFrame): The original DataFrame from which columns will be removed.
    - columns (list of str): A list of strings representing the names of the columns to be removed.

    Returns:
    - pd.DataFrame: A new DataFrame with the specified columns removed.
    """
    dataframe = data.drop(columns, axis=1)
    return dataframe


def custom_train_test_split(X, y, size=0.2):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size)
    return X_train, X_test, y_train, y_test


def custom_decision_tree_classification(
    criterion_c="gini",
    max_depth_c=None,
    min_samples_split_c=2,
    min_samples_leaf_c=2,
    ccp_alpha_c=0.0,
):
    model = DecisionTreeClassifier(
        criterion=criterion_c,
        max_depth=max_depth_c,
        min_samples_split=min_samples_split_c,
        min_samples_leaf=min_samples_leaf_c,
        ccp_alpha=ccp_alpha_c,
    )
    return model


def train_and_predict(model, X_train, y_train, X_test):
    """
    Trains a model and predicts outcomes for the given test data.
    This function uses Streamlit's memoization to cache the model training and prediction steps,
    improving performance for repeated calls with unchanged data.

    Args:
        model: The machine learning model to be trained. Must be hashable by Streamlit.
        X_train (pd.DataFrame or np.ndarray): Training data features.
        y_train (pd.Series or np.ndarray): Training data labels/targets.
        X_test (pd.DataFrame or np.ndarray): Test data features.

    Returns:
        A tuple containing:
        - model: The trained machine learning model.
        - pred: Predictions made by the model on X_test.
    """
    model.fit(X_train, y_train)
    pred = model.predict(X_test)
    return model, pred


def custom_random_forest_classification(
    n_estimators_c=100,
    criterion_c="squared_error",
    max_depth_c=None,
    min_samples_split_c=2,
    min_samples_leaf_c=2,
    ccp_alpha_c=0.0,
):
    model = RandomForestClassifier(
        n_estimators=n_estimators_c,
        max_depth=max_depth_c,
        min_samples_split=min_samples_split_c,
        min_samples_leaf=min_samples_leaf_c,
        ccp_alpha=ccp_alpha_c,
    )
    return model


def custom_svc(kernel_c="rbf", degree_c=3):
    model = SVC(kernel=kernel_c, degree=degree_c)
    return model


def custom_mlp_classifier(
    activation_func_c="relu",
    solver_c="adam",
):
    model = MLPClassifier(activation=activation_func_c, solver=solver_c)
    return model


def confusion_matrix_visualization(y_true, y_pred, input_color="Blues"):
    cm = confusion_matrix(y_true, y_pred)
    fig = plt.figure(figsize=(10, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap=input_color, cbar=False)
    plt.xlabel("Predicted labels")
    plt.ylabel("True labels")
    plt.title("Confusion Matrix")
    st.pyplot(fig)


if __name__ == "__main__":
    load_widget_state()
    main()
